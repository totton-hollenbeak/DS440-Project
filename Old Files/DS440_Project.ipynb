{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, hamming_loss, roc_auc_score, average_precision_score\n",
    "from medmnist import ChestMNIST\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_split, image_nxn_size, n_observations):\n",
    "    data = ChestMNIST(split=data_split, download=True, size=image_nxn_size)\n",
    "\n",
    "    if n_observations > 0:\n",
    "        images = data.imgs[0:n_observations]\n",
    "        labels = data.labels[0:n_observations]\n",
    "    else:      \n",
    "        images = data.imgs\n",
    "        labels = data.labels\n",
    "\n",
    "    del data\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = load_data(data_split=\"train\", image_nxn_size=28, n_observations=1000)\n",
    "validation_images, validation_labels = load_data(data_split=\"val\", image_nxn_size=28, n_observations=1000)\n",
    "test_images, test_labels = load_data(data_split=\"test\", image_nxn_size=28, n_observations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_image = train_images[0]\n",
    "pixels = raw_image.flatten()\n",
    "\n",
    "plt.hist(pixels, bins=50, alpha=0.7, color='blue', edgecolor='black', label=f'Pixel Mean: {np.mean(pixels):.4f} | Std Dev: {np.std(pixels):.4f}')\n",
    "plt.legend(loc='upper center')\n",
    "plt.title('Distribution of Pixel Intensities in the Image')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Number of Pixels')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224), interpolation=Image.NEAREST),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "def preprocess_images(images):\n",
    "    transformed_images = []\n",
    "\n",
    "    for img in images:\n",
    "        img = Image.fromarray(img.astype(np.uint8))\n",
    "        transformed_img = data_transform(img)\n",
    "        transformed_images.append(transformed_img)\n",
    "\n",
    "    return torch.stack(transformed_images)\n",
    "\n",
    "preprocessed_images = preprocess_images(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_image = preprocessed_images[0]\n",
    "pixels = raw_image.flatten()\n",
    "\n",
    "mean_pixel = torch.mean(pixels).item()\n",
    "std_pixel = torch.std(pixels).item()\n",
    "\n",
    "plt.hist(pixels.numpy(), bins=50, alpha=0.7, color='blue', edgecolor='black', label=f'Pixel Mean: {mean_pixel:.4f} | Std Dev: {std_pixel:.4f}')\n",
    "plt.legend(loc='upper center')\n",
    "plt.title('Distribution of Pixel Intensities in the Image')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Number of Pixels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = preprocess_images(train_images)\n",
    "x_validation_tensor = preprocess_images(validation_images)\n",
    "x_test_tensor = preprocess_images(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.tensor(train_labels)\n",
    "y_validation_tensor = torch.tensor(validation_labels)\n",
    "y_test_tensor = torch.tensor(test_labels)\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "validation_dataset = TensorDataset(x_validation_tensor, y_validation_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=64, shuffle=False)  \n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT, progress=True)\n",
    "\n",
    "if True:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # for param in model.layer3.parameters():\n",
    "    #     param.requires_grad = True\n",
    "\n",
    "    for param in model.layer4.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, train_labels.shape[1], bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.1)\n",
    "scheduler = StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
    "\n",
    "#class_counts = torch.sum(y_train_tensor, dim=0).float()\n",
    "#pos_weight = 1.0 / class_counts\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"best_transfer_learning_model.pth\"\n",
    "best_loss = np.inf\n",
    "best_score = 0\n",
    "best_epoch = 0\n",
    "sigmoid_threshold = 0.5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for inputs, targets in tqdm.tqdm(train_loader, desc=\"Training: \"):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        targets = targets.float()\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    validation_loss = 0.0\n",
    "    validation_accuracy = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for validation_inputs, validation_targets in validation_loader:\n",
    "            validation_outputs = model(validation_inputs)\n",
    "            validation_targets = validation_targets.float()\n",
    "            validation_loss += criterion(validation_outputs, validation_targets)\n",
    "\n",
    "            probabilities = torch.sigmoid(validation_outputs)\n",
    "            predictions = (probabilities > sigmoid_threshold).float()\n",
    "\n",
    "            all_targets.extend(validation_targets)\n",
    "            all_predictions.extend(probabilities)\n",
    "\n",
    "    validation_score = roc_auc_score(all_targets, all_predictions, average=\"macro\")\n",
    "    validation_loss /= len(validation_loader.dataset)\n",
    "\n",
    "    if validation_loss < best_loss:\n",
    "        best_loss = validation_loss\n",
    "    \n",
    "    if validation_score > best_score:\n",
    "        best_score = validation_score\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}, Validation Loss: {validation_loss}, ROC AUC: {validation_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"best_transfer_learning_model.pth\", weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_inputs, test_targets in tqdm.tqdm(test_loader, desc=\"Testing:\"):\n",
    "        test_outputs = model(test_inputs)\n",
    "        test_targets = test_targets.float()\n",
    "        test_loss += criterion(test_outputs, test_targets)\n",
    "\n",
    "        probabilities = torch.sigmoid(test_outputs)\n",
    "        predictions = (probabilities > sigmoid_threshold).float()\n",
    "\n",
    "        all_targets.extend(test_targets)\n",
    "        all_predictions.extend(predictions)\n",
    "\n",
    "print(all_predictions)\n",
    "test_loss /= len(test_loader.dataset)\n",
    "test_hamming_loss = hamming_loss(all_targets, all_predictions)\n",
    "test_accuracy = accuracy_score(all_targets, all_predictions)\n",
    "test_precision = precision_score(all_targets, all_predictions, average=\"macro\")\n",
    "test_recall = recall_score(all_targets, all_predictions, average=\"macro\")\n",
    "test_f1_score = f1_score(all_targets, all_predictions, average=\"macro\")\n",
    "test_roc_auc = roc_auc_score(all_targets, all_predictions, average=\"macro\")\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Hamming Loss: {test_hamming_loss}\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"Precision: {test_precision}\")\n",
    "print(f\"Recall: {test_recall}\")\n",
    "print(f\"F1 Score: {test_f1_score}\")\n",
    "print(f\"ROC AUC: {test_roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"best_transfer_learning_model.pth\", weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "target_layers = [model.layer4[-1]]\n",
    "\n",
    "image = Image.open(\"./Example Images/Infiltration.PNG\").convert(\"RGB\")\n",
    "input_tensor = data_transform(image).unsqueeze(0)\n",
    "\n",
    "targets = [ClassifierOutputTarget(i) for i in range(0, 15)]\n",
    "\n",
    "with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "    rgb_img = np.array(image) / 255.0\n",
    "    rgb_img = cv2.resize(rgb_img, (224, 224))\n",
    "\n",
    "    visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "    \n",
    "    plt.imshow(visualization)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"best_transfer_learning_model.pth\", weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "labels = {\n",
    "    0: \"Atelectasis\",\n",
    "    1: \"Cardiomegaly\",\n",
    "    2: \"Effusion\",\n",
    "    3: \"Infiltration\",\n",
    "    4: \"Mass\",\n",
    "    5: \"Nodule\",\n",
    "    6: \"Pneumonia\",\n",
    "    7: \"Pneumothorax\",\n",
    "    8: \"Consolidation\",\n",
    "    9: \"Edema\",\n",
    "    10: \"Emphysema\",\n",
    "    11: \"Fibrosis\",\n",
    "    12: \"Pleural\",\n",
    "    13: \"Hernia\"\n",
    "}\n",
    "\n",
    "target_layers = [model.layer4[-1]]\n",
    "\n",
    "image = Image.open(\"./Example Images/Atelectasis_Effusion_Infiltration.PNG\").convert(\"RGB\")\n",
    "input_tensor = data_transform(image).unsqueeze(0)\n",
    "\n",
    "targets = [ClassifierOutputTarget(i) for i in range(0, 14)]\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, target in enumerate(targets):\n",
    "    with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "        grayscale_cam = cam(input_tensor=input_tensor, targets=[target])\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "        rgb_img = np.array(image) / 255.0\n",
    "        rgb_img = cv2.resize(rgb_img, (224, 224))\n",
    "\n",
    "        visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "        ax = axes[idx]\n",
    "        ax.imshow(visualization)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"{labels[idx]}\")\n",
    "\n",
    "for j in range(len(targets), len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT, progress=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 14, bias=True)\n",
    "model.load_state_dict(torch.load(\"best_transfer_learning_model_1.pth\", weights_only=True))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS440_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
